project:
  name: "fagus_npe_production_v9"  # Updated name
  seed: 1234567
  output_dir: "results_production" # New output dir

observed:
  pooldata_rdata: "observed_data/Pooldata_demography.RData"
  pooldata_object: "filt.pooldata"
  groups_csv: "config/groups_6clusters.csv"
  target_cov: 10

simulation:
  slim_binary: "/home/j_morando/.local/bin/slim"
  slim_template: "templates/model.slim.tpl"
  trees_tmpdir: "/dev/shm"
  
  pop_order: ['p1', 'p3', 'p4', 'p5', 'p7', 'p8']
  
  # ---- Adaptive scaling ----
  max_scale_factor: 1000
  safe_min_diploids: 10

  burnin: 3000
  gens: 40001  # INCREASED from 30k to 100k to allow older splits if needed
  genome_length: 2e6 # KEPT at 1Mb (matches your R script fix)
  recombination_rate: 1e-8
  
  mutation_overlay:
    enable: true
    mu: 7.77e-9
    model: "binary"
    target_snps: null
  
  samples_per_group_haploid: 10

priors:
  times:
    # INCREASED MAX to 99,900 to prevent hitting the ceiling
    T_BG01:      {min:  1, max: 40000}
    T_CORE:      {min:  1, max: 40000}
    T_SOUTH_LOW: {min:  1, max: 40000}
    T_SOUTH_MID: {min:  1, max: 40000}
    T_EAST:      {min:  1, max: 40000}
    T_INT:       {min:  1, max: 40000}
    T_CENTRAL:   {min:  1, max: 40000}
    T_PYRENEES:  {min:  1, max: 40000}
  
  sizes:
    N0:          {dist: fixed, value: 10000}
    N_CORE:      {dist: fixed, value: 10000}
    
    # DECREASED MIN to 200 (previous run hit the 1200 floor)
    N_BG01:      {dist: loguniform, min:  500, max: 60000}
    N_SOUTH_LOW: {dist: loguniform, min:  500, max: 60000}
    N_SOUTH_MID: {dist: loguniform, min:  500, max: 60000}
    N_EAST:      {dist: loguniform, min:  500, max: 60000}
    N_INT:       {dist: loguniform, min:  500, max: 60000}
    N_CENTRAL:   {dist: loguniform, min:  500, max: 60000}
    N_PYRENEES:  {dist: loguniform, min:  500, max: 60000}
  
  demography_extras:
    enable: true  # ENABLED
    bottleneck:
      mode: per_population
      time_fraction: {dist: uniform, min: 0.1, max: 0.7}
      # ALLOW STRONGER BOTTLENECKS (down to 1% size)
      size_fraction: {dist: loguniform, min: 0.0001, max: 0.6}
      # ALLOW LONGER DURATION (up to 500 gens)
      duration_gens: {dist: discrete_uniform, min: 5, max: 20000}
    expansion:
      enable: false
    migration:
      enable: false

npe:
  n_sims: 20000 # Keep at 200k for robust inference
  batch_size: 1024
  num_workers: 60
  standardize_x: true
  standardize_theta: true
  val_frac: 0.1
  max_val: 2000
  min_val: 50
  lr: 0.0003
  weight_decay: 0.0004
  max_epochs: 300
  early_stop_patience: 30
  n_posterior_samples: 10000
  dropout: 0.1
